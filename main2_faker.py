import json
import pandas as pd
from pathlib import Path
import sys
import random
import traceback
from data_generators import replace_and_label, TAGS, DATAGEN
from faker import Faker

fake = Faker(locale='ru_RU')

def load_dataset(file_path: str) -> list:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç [{'message': '—Ç–µ–∫—Å—Ç'}, ...]
    """
    file_path = Path(file_path)
    if not file_path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
    
    ext = file_path.suffix.lower()
    
    try:
        if ext == '.csv':
            return _load_from_csv(file_path)
        elif ext == '.json':
            return _load_from_json(file_path)
        elif ext in ['.jsonl', '.jl']:
            return _load_from_jsonl(file_path)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {ext}. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: .csv, .json, .jsonl")
            
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {str(e)}")

def _load_from_csv(file_path: Path) -> list:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–∞"""
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
    encodings = ['utf-8', 'cp1251', 'utf-8-sig']
    for encoding in encodings:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            if not df.empty:
                break
        except UnicodeDecodeError:
            continue
    else:
        df = pd.read_csv(file_path)
    
    # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
    message_col = None
    for col in ['message', 'text', 'content', 'sentence', 'utterance']:
        if col in df.columns:
            message_col = col
            break
    
    if message_col is None:
        message_col = df.columns[0]
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
    result = []
    for text in df[message_col].dropna():
        if isinstance(text, str) and text.strip():
            result.append({"message": text.strip()})
    
    return result

def _load_from_json(file_path: Path) -> list:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if isinstance(data, list):
        return _process_json_list(data)
    elif isinstance(data, dict):
        if 'data' in data and isinstance(data['data'], list):
            return _process_json_list(data['data'])
        elif 'items' in data and isinstance(data['items'], list):
            return _process_json_list(data['items'])
        elif 'messages' in data and isinstance(data['messages'], list):
            return _process_json_list(data['messages'])
        else:
            for key, value in data.items():
                if isinstance(value, list):
                    return _process_json_list(value)
    
    raise ValueError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON —Ñ–∞–π–ª–∞")

def _load_from_jsonl(file_path: Path) -> list:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSONL —Ñ–∞–π–ª–∞"""
    result = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            
            try:
                item = json.loads(line)
                if isinstance(item, dict) and 'message' in item:
                    text = item['message']
                    if isinstance(text, str) and text.strip():
                        result.append({"message": text.strip()})
                else:
                    for key in ['text', 'content', 'sentence', 'utterance', 'message']:
                        if key in item and isinstance(item[key], str) and item[key].strip():
                            result.append({"message": item[key].strip()})
                            break
            
            except json.JSONDecodeError:
                continue
    
    return result

def _process_json_list(data_list: list) -> list:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö"""
    result = []
    
    for item in data_list:
        if not isinstance(item, dict):
            continue
        
        message_value = None
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ –ø–æ–ª–µ–π
        for field in ['message', 'text', 'content', 'sentence', 'utterance']:
            if field in item and isinstance(item[field], str) and item[field].strip():
                message_value = item[field].strip()
                break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø–æ–ª–µ
        if message_value is None:
            for key, value in item.items():
                if isinstance(value, str) and value.strip():
                    message_value = value.strip()
                    break
        
        if message_value:
            result.append({"message": message_value})
    
    return result

def save_dataset(data: list, output_path: str, output_format: str) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    """
    output_path = Path(output_path)
    output_format = output_format.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –¥–∞—Ç–∞—Å–µ—Ç —Ä–∞–∑–º–µ—Ç–∫—É (entities)
    has_entities = any('entities' in item for item in data)
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    if output_format == 'json':
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    elif output_format == 'csv':
        if has_entities:
            print("‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: CSV —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã. –°—É—â–Ω–æ—Å—Ç–∏ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏.")
            # –°–æ–∑–¥–∞–µ–º DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ text –∏ entities
            df = pd.DataFrame([
                {
                    'text': item['text'],
                    'entities': json.dumps(item['entities'], ensure_ascii=False)
                } for item in data
            ])
        else:
            df = pd.DataFrame(data)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    elif output_format in ['jsonl', 'jl']:
        with open(output_path, 'w', encoding='utf-8') as f:
            for item in data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    else:
        raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {output_format}. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: json, csv, jsonl")

def display_preview(data: list, title: str, num_items: int = 3) -> None:
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –ø—Ä–µ–≤—å—é –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print(f"\n{title}:")
    print("-" * 50)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
    is_labeled = any('entities' in item for item in data)
    
    if is_labeled:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        for i, item in enumerate(data[:num_items], 1):
            print(f"{i}. –¢–µ–∫—Å—Ç: {item['text']}")
            print("   –°—É—â–Ω–æ—Å—Ç–∏:")
            for entity in item.get('entities', []):
                entity_text = item['text'][entity[0]:entity[1]]
                print(f"     - {entity[2]}: '{entity_text}' [{entity[0]}:{entity[1]}]")
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        for i, item in enumerate(data[:num_items], 1):
            print(f"{i}. {item['message']}")
    
    if len(data) > num_items:
        print(f"... –∏ –µ—â–µ {len(data) - num_items} –∑–∞–ø–∏—Å–µ–π")
    print("-" * 50)

def process_dataset_with_faker(input_data):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç —Å –ø–æ–º–æ—â—å—é —Ñ–µ–π–∫–µ—Ä–∞
    
    Args:
        input_data (list): –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{'message': '—Ç–µ–∫—Å—Ç —Å —Ç–µ–≥–∞–º–∏'}, ...]
    
    Returns:
        list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ spaCy [{'text': '...', 'entities': [...]}, ...]
    """
    processed_data = []
    total_entities = 0
    
    print("\nüîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é —Ñ–µ–π–∫–µ—Ä–∞...")
    print("-" * 60)
    
    for i, item in enumerate(input_data, 1):
        if i % 100 == 0:
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i} —Å–æ–æ–±—â–µ–Ω–∏–π...")
        
        try:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–µ–π–∫–µ—Ä –∫ –∫–∞–∂–¥–æ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é
            result = replace_and_label(item['message'])
            processed_data.append(result)
            total_entities += len(result['entities'])
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è {i}: {str(e)}")
            print(f"   –¢–µ–∫—Å—Ç: {item['message']}")
    
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(input_data)} —Å–æ–æ–±—â–µ–Ω–∏–π")
    print(f"üìä –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {total_entities} —Å—É—â–Ω–æ—Å—Ç–µ–π")
    
    return processed_data

def count_tags_in_dataset(data):
    """
    –°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É—â–Ω–æ—Å—Ç–µ–π –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
    
    Args:
        data (list): –î–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{'text': '...', 'entities': [...]}, ...]
    
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–∞–∂–¥–æ–π —Å—É—â–Ω–æ—Å—Ç–∏
    """
    tag_counts = {}
    
    for item in data:
        for entity in item['entities']:
            tag = entity[2]  # entity[2] - —ç—Ç–æ —Ç–∏–ø —Å—É—â–Ω–æ—Å—Ç–∏
            tag_counts[tag] = tag_counts.get(tag, 0) + 1
    
    return tag_counts

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º"""
    print("üöÄ –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 70)
    
    # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã
    print("\nüîß –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
    print("   1. –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ (csv/json/jsonl)")
    print("   2. –†–µ–∂–∏–º —Å —Ñ–µ–π–∫–µ—Ä–æ–º: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è NER")
    
    while True:
        mode = input("\nüî¢ –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä —Ä–µ–∂–∏–º–∞ (1/2): ").strip()
        if mode in ['1', '2']:
            break
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ 1 –∏–ª–∏ 2.")
    
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    input_file = input("üìÅ –í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (csv/json/jsonl): ").strip()
    
    if mode == '1':
        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        print("\nüíæ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è:")
        print("   - json  : –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON")
        print("   - csv   : –¢–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç CSV")
        print("   - jsonl : JSON Lines (–ø–æ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏ –Ω–∞ —Å—Ç—Ä–æ–∫—É)")
        
        while True:
            output_format = input("\nüî§ –í–≤–µ–¥–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (json/csv/jsonl): ").strip().lower()
            if output_format in ['json', 'csv', 'jsonl']:
                break
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∏–∑: json, csv, jsonl")
    
    else:
        # –†–µ–∂–∏–º —Å —Ñ–µ–π–∫–µ—Ä–æ–º
        print("\nüí° –í —Ä–µ–∂–∏–º–µ —Ñ–µ–π–∫–µ—Ä–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏:")
        print("   - json  : –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è spaCy)")
        print("   - jsonl : JSON Lines")
        
        while True:
            output_format = input("\nüî§ –í–≤–µ–¥–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (json/jsonl): ").strip().lower()
            if output_format in ['json', 'jsonl']:
                break
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∏–∑: json, jsonl")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        print(f"\n‚è≥ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ {input_file}...")
        data = load_dataset(input_file)
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —Å–æ–æ–±—â–µ–Ω–∏–π")
        
        # –í —Ä–µ–∂–∏–º–µ —Ñ–µ–π–∫–µ—Ä–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        if mode == '2':
            print("\n‚ú® –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –≤ —Ä–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            data = process_dataset_with_faker(data)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–µ–≥–∞–º
            tag_stats = count_tags_in_dataset(data)
            print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å—É—â–Ω–æ—Å—Ç—è–º:")
            print("-" * 40)
            for tag, count in sorted(tag_stats.items(), key=lambda x: x[1], reverse=True):
                print(f"{tag}: {count}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö
        preview_title = "üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ" if mode == '1' else "‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"
        display_preview(data, preview_title)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        input_path = Path(input_file)
        output_filename = f"{input_path.stem}_{'labeled' if mode == '2' else 'converted'}.{output_format}"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ {output_format}...")
        save_dataset(data, output_filename, output_format)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        print(f"\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª...")
        if output_format == 'json':
            with open(output_filename, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
        elif output_format == 'csv':
            saved_df = pd.read_csv(output_filename)
            if 'text' in saved_df.columns and 'entities' in saved_df.columns:
                # –≠—Ç–æ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ CSV
                saved_data = []
                for _, row in saved_df.iterrows():
                    try:
                        entities = json.loads(row['entities'])
                        saved_data.append({'text': row['text'], 'entities': entities})
                    except:
                        saved_data.append({'text': row['text'], 'entities': []})
            else:
                # –≠—Ç–æ –æ–±—ã—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ CSV
                message_col = saved_df.columns[0]
                saved_data = [{"message": str(row[message_col]).strip()} 
                            for _, row in saved_df.iterrows() if pd.notna(row[message_col])]
        elif output_format in ['jsonl', 'jl']:
            saved_data = []
            with open(output_filename, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        saved_data.append(json.loads(line))
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_title = "‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è" if mode == '1' else "‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–∑–º–µ—Ç–∫–∏"
        display_preview(saved_data, result_title)
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        file_size = Path(output_filename).stat().st_size / 1024  # –≤ KB
        print(f"\nüìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ:")
        print(f"   üìÑ –ò–º—è —Ñ–∞–π–ª–∞: {output_filename}")
        print(f"   üìç –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {Path(output_filename).resolve()}")
        print(f"   üíæ –†–∞–∑–º–µ—Ä: {file_size:.1f} KB")
        print(f"   üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(saved_data)}")
        
        if mode == '2':
            total_entities = sum(len(item.get('entities', [])) for item in saved_data)
            print(f"   üè∑  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: {total_entities}")
        
        print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∏ {'–≥–æ—Ç–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è' if mode == '1' else '–≥–æ—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è NER –º–æ–¥–µ–ª–∏'}!")
        
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()